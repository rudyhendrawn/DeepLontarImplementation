{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a method to split the dataset into train and test set\n",
    "def split_dataset(dataset, train_ratio=0.8):\n",
    "\t\"\"\"\n",
    "\tFunction that can be used to split the dataset into train and test set.\n",
    "\tArgs:\n",
    "\t\tdataset (DeepLontarDataset): Dataset to split\n",
    "\t\ttrain_ratio (float): Ratio of the dataset to use for training\n",
    "\tReturns:\n",
    "\t\ttrain_dataset (DeepLontarDataset): Training dataset\n",
    "\t\ttest_dataset (DeepLontarDataset): Test dataset\n",
    "\t\"\"\"\n",
    "\ttrain_size = int(train_ratio * len(dataset))\n",
    "\ttest_size = len(dataset) - train_size\n",
    "\ttrain_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\treturn train_dataset, test_dataset\n",
    "\n",
    "# Create a class that Implements YOLOv3 model architecture\n",
    "# The input model is the image data and its annotations (bounding boxes) and class_id in format [xmin, ymin, xmax, ymax, class_id]\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from __future__ import division\n",
    "\n",
    "def parse_cfg(cfg_file):\n",
    "\t\"\"\"\n",
    "\tTakes a configuration file.\n",
    "\n",
    "\tReturns a list of blocks. Each blocks describes a block in the neural\n",
    "\tnetwork to be built. Block is represented as a dictionary in the list.\n",
    "\tSource: https://blog.paperspace.com/how-to-implement-a-yolo-v3-object-detector-from-scratch-in-pytorch-part-2/\n",
    "\t\"\"\"\n",
    "\twith open(cfg_file, 'r') as f:\n",
    "\t\tlines = f.read().split('\\n')\n",
    "\t\tlines = [x for x in lines if len(x) > 0]\n",
    "\t\tlines = [x for x in lines if x[0] != '#']\n",
    "\t\tlines = [x.rstrip().lstrip() for x in lines]\n",
    "\t\n",
    "\tblock = {}\n",
    "\tblocks = []\n",
    "\t\n",
    "\tfrom line in lines:\n",
    "\t\tif line[0] == \"[\":\t\t\t\t# This marks the start of a new block\n",
    "\t\t\tif len(block) != 0:\t\t\t# If block is not empty, implies it is storing values of previous block.\n",
    "\t\t\t\tblocks.append(block)\t# add it the blocks list\n",
    "\t\t\t\tblock = {}\t\t\t\t# re-init the block\n",
    "\t\t\tblock[\"type\"] = line[1:-1].rstrip()\n",
    "\t\telse:\n",
    "\t\t\tkey, value = line.split(\"=\")\n",
    "\t\t\tblock[key.rstrip()] = value.lstrip()\n",
    "\n",
    "\tblocks.append(block)\n",
    "\treturn blocks\n",
    "\t\n",
    "def create_modules(blocks):\n",
    "\t\"\"\"\n",
    "\tNow we are going to use the list returned \n",
    "\tby the above parse_cfg to construct PyTorch modules \n",
    "\tfor the blocks present in the config file.\n",
    "\n",
    "\tThe create_modules function takes a list blocks returned by the parse_cfg function.\n",
    "\t\"\"\"\n",
    "\tnet_info = blocks[0]\t# Captures the information about the input and pre-processing\n",
    "\tmodule_list = nn.ModuleList()\n",
    "\tprev_filters = 3\n",
    "\toutput_filters = []\n",
    "\n",
    "\tfor index, x in enumerate(blocks[1:]):\n",
    "\t\tmodule = nn.Sequential()\n",
    "\n",
    "\t\t# check the type of block\n",
    "\t\t# create a new module for the block\n",
    "\t\t# append to module_list\n",
    "\t\tif (x['type'] == 'convolutional'):\n",
    "\t\t\t# Get the info about the layer\n",
    "\t\t\tactivation = x['activation']\n",
    "\t\t\ttry:\n",
    "\t\t\t\tbatch_normalize = int(x['batch_normalize'])\n",
    "\t\t\t\tbias = False\n",
    "\t\t\texcept:\n",
    "\t\t\t\tbatch_normalize = 0\n",
    "\t\t\t\tbias = True\n",
    "\t\t\t\n",
    "\t\t\tfilters = int(x['filters'])\n",
    "\t\t\tkernel_size = int(x['size'])\n",
    "\t\t\tstride = int(x['stride'])\n",
    "\t\t\tpad = (kernel_size - 1) // 2 if int(x['pad']) else 0\n",
    "\t\t\t\n",
    "\t\t\t# Add the convolutional layer\n",
    "\t\t\tconv = nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias=bias)\n",
    "\t\t\tmodule.add_module('conv_{0}'.format(index), conv)\n",
    "\n",
    "\t\t\t# Add the Batch Norm Layer\n",
    "\t\t\tif batch_normalize:\n",
    "\t\t\t\tbn = nn.BatchNorm2d(filters)\n",
    "\t\t\t\tmodule.add_module('batch_norm_{0}'.format(index), bn)\n",
    "\n",
    "\t\t\t# Check the activation.\n",
    "\t\t\t# It is either Linear or a Leaky ReLU for YOLO\n",
    "\t\t\tif activation == 'leaky':\n",
    "\t\t\t\tactivn = nn.LeakyReLU(0.1, inplace=True)\n",
    "\t\t\t\tmodule.add_module('leaky_{0}'.format(index), activn)\n",
    "\n",
    "\t\t# If it's an upsampling layer\n",
    "\t\t# We use Bilinear2dUpsampling\n",
    "\t\telif (x['type'] == 'upsample'):\n",
    "\t\t\tstride = int(x['stride'])\n",
    "\t\t\tupsample = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "\t\t\tmodule.add_module('upsample_{}'.format(index), upsample)\n",
    "\t\t\n",
    "\t\t# If it is a route layer\n",
    "\t\telif (x['type'] == 'route'):\n",
    "\t\t\tx['layers'] = x['layers'].split(',')\n",
    "\t\t\t# Start  of a route\n",
    "\t\t\tstart = int(x['layers'][0])\n",
    "\t\t\t# end, if there exists one.\n",
    "\t\t\ttry:\n",
    "\t\t\t\tend = int(x['layers'][1])\n",
    "\t\t\texcept:\n",
    "\t\t\t\tend = 0\n",
    "\t\t\t# Positive annotation\n",
    "\t\t\tif start > 0: \n",
    "\t\t\t\tstart = start - index\n",
    "\t\t\t\n",
    "\t\t\tif end > 0: \n",
    "\t\t\t\tend = end - index\n",
    "\t\t\t\n",
    "\t\t\troute = EmptyLayer()\n",
    "\t\t\tmodule.add_module('route_{0}'.format(index), route)\n",
    "\t\t\tif end < 0:\n",
    "\t\t\t\tfilters = output_filters[index + start] + output_filters[index + end]\n",
    "\t\t\telse:\n",
    "\t\t\t\tfilters = output_filters[index + start]\n",
    "\t\t\t\t\n",
    "\t\t# shortcut corresponds to skip connection\n",
    "\t\telif x['type'] == 'shortcut':\n",
    "\t\t\tshortcut = EmptyLayer()\n",
    "\t\t\tmodule.add_module('shortcut_{}'.format(index), shortcut)\n",
    "\n",
    "class EmptyLayer(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(EmptyLayer, self).__init__()\n",
    "\n",
    "class DetectionLayer(nn.Module):\n",
    "\tdef __init__(self, anchors):\n",
    "\t\tsuper(DetectionLayer, self).__init__()\n",
    "\t\tself.anchors = anchors\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "942bd951272a0de8204639ca0c1bae75e8bf0bc00017a9c7601c940079018a11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
