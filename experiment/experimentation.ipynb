{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a method to split the dataset into train and test set\n",
    "def split_dataset(dataset, train_ratio=0.8):\n",
    "\t\"\"\"\n",
    "\tFunction that can be used to split the dataset into train and test set.\n",
    "\tArgs:\n",
    "\t\tdataset (DeepLontarDataset): Dataset to split\n",
    "\t\ttrain_ratio (float): Ratio of the dataset to use for training\n",
    "\tReturns:\n",
    "\t\ttrain_dataset (DeepLontarDataset): Training dataset\n",
    "\t\ttest_dataset (DeepLontarDataset): Test dataset\n",
    "\t\"\"\"\n",
    "\ttrain_size = int(train_ratio * len(dataset))\n",
    "\ttest_size = len(dataset) - train_size\n",
    "\ttrain_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\treturn train_dataset, test_dataset\n",
    "\n",
    "# Create a class that Implements YOLOv3 model architecture\n",
    "# The input model is the image data and its annotations (bounding boxes) and class_id in format [xmin, ymin, xmax, ymax, class_id]\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from __future__ import division\n",
    "\n",
    "def parse_cfg(cfg_file):\n",
    "\t\"\"\"\n",
    "\tTakes a configuration file.\n",
    "\n",
    "\tReturns a list of blocks. Each blocks describes a block in the neural\n",
    "\tnetwork to be built. Block is represented as a dictionary in the list.\n",
    "\tSource: https://blog.paperspace.com/how-to-implement-a-yolo-v3-object-detector-from-scratch-in-pytorch-part-2/\n",
    "\t\"\"\"\n",
    "\twith open(cfg_file, 'r') as f:\n",
    "\t\tlines = f.read().split('\\n')\n",
    "\t\tlines = [x for x in lines if len(x) > 0]\n",
    "\t\tlines = [x for x in lines if x[0] != '#']\n",
    "\t\tlines = [x.rstrip().lstrip() for x in lines]\n",
    "\t\n",
    "\tblock = {}\n",
    "\tblocks = []\n",
    "\t\n",
    "\tfor line in lines:\n",
    "\t\tif line[0] == \"[\":\t\t\t\t# This marks the start of a new block\n",
    "\t\t\tif len(block) != 0:\t\t\t# If block is not empty, implies it is storing values of previous block.\n",
    "\t\t\t\tblocks.append(block)\t# add it the blocks list\n",
    "\t\t\t\tblock = {}\t\t\t\t# re-init the block\n",
    "\t\t\tblock[\"type\"] = line[1:-1].rstrip()\n",
    "\t\telse:\n",
    "\t\t\tkey, value = line.split(\"=\")\n",
    "\t\t\tblock[key.rstrip()] = value.lstrip()\n",
    "\n",
    "\tblocks.append(block)\n",
    "\treturn blocks\n",
    "\t\n",
    "def create_modules(blocks):\n",
    "\t\"\"\"\n",
    "\tNow we are going to use the list returned \n",
    "\tby the above parse_cfg to construct PyTorch modules \n",
    "\tfor the blocks present in the config file.\n",
    "\n",
    "\tThe create_modules function takes a list blocks returned by the parse_cfg function.\n",
    "\t\"\"\"\n",
    "\tnet_info = blocks[0]\t# Captures the information about the input and pre-processing\n",
    "\tmodule_list = nn.ModuleList()\n",
    "\tprev_filters = 3\n",
    "\toutput_filters = []\n",
    "\n",
    "\tfor index, x in enumerate(blocks[1:]):\n",
    "\t\tmodule = nn.Sequential()\n",
    "\n",
    "\t\t# check the type of block\n",
    "\t\t# create a new module for the block\n",
    "\t\t# append to module_list\n",
    "\t\tif (x['type'] == 'convolutional'):\n",
    "\t\t\t# Get the info about the layer\n",
    "\t\t\tactivation = x['activation']\n",
    "\t\t\ttry:\n",
    "\t\t\t\tbatch_normalize = int(x['batch_normalize'])\n",
    "\t\t\t\tbias = False\n",
    "\t\t\texcept:\n",
    "\t\t\t\tbatch_normalize = 0\n",
    "\t\t\t\tbias = True\n",
    "\t\t\t\n",
    "\t\t\tfilters = int(x['filters'])\n",
    "\t\t\tkernel_size = int(x['size'])\n",
    "\t\t\tstride = int(x['stride'])\n",
    "\t\t\tpad = (kernel_size - 1) // 2 if int(x['pad']) else 0\n",
    "\t\t\t\n",
    "\t\t\t# Add the convolutional layer\n",
    "\t\t\tconv = nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias=bias)\n",
    "\t\t\tmodule.add_module('conv_{0}'.format(index), conv)\n",
    "\n",
    "\t\t\t# Add the Batch Norm Layer\n",
    "\t\t\tif batch_normalize:\n",
    "\t\t\t\tbn = nn.BatchNorm2d(filters)\n",
    "\t\t\t\tmodule.add_module('batch_norm_{0}'.format(index), bn)\n",
    "\n",
    "\t\t\t# Check the activation.\n",
    "\t\t\t# It is either Linear or a Leaky ReLU for YOLO\n",
    "\t\t\tif activation == 'leaky':\n",
    "\t\t\t\tactivn = nn.LeakyReLU(0.1, inplace=True)\n",
    "\t\t\t\tmodule.add_module('leaky_{0}'.format(index), activn)\n",
    "\n",
    "\t\t# If it's an upsampling layer\n",
    "\t\t# We use Bilinear2dUpsampling\n",
    "\t\telif (x['type'] == 'upsample'):\n",
    "\t\t\tstride = int(x['stride'])\n",
    "\t\t\tupsample = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "\t\t\tmodule.add_module('upsample_{}'.format(index), upsample)\n",
    "\t\t\n",
    "\t\t# If it is a route layer\n",
    "\t\telif (x['type'] == 'route'):\n",
    "\t\t\tx['layers'] = x['layers'].split(',')\n",
    "\t\t\t# Start  of a route\n",
    "\t\t\tstart = int(x['layers'][0])\n",
    "\t\t\t# end, if there exists one.\n",
    "\t\t\ttry:\n",
    "\t\t\t\tend = int(x['layers'][1])\n",
    "\t\t\texcept:\n",
    "\t\t\t\tend = 0\n",
    "\t\t\t# Positive annotation\n",
    "\t\t\tif start > 0: \n",
    "\t\t\t\tstart = start - index\n",
    "\t\t\t\n",
    "\t\t\tif end > 0: \n",
    "\t\t\t\tend = end - index\n",
    "\t\t\t\n",
    "\t\t\troute = EmptyLayer()\n",
    "\t\t\tmodule.add_module('route_{0}'.format(index), route)\n",
    "\t\t\tif end < 0:\n",
    "\t\t\t\tfilters = output_filters[index + start] + output_filters[index + end]\n",
    "\t\t\telse:\n",
    "\t\t\t\tfilters = output_filters[index + start]\n",
    "\t\t\t\t\n",
    "\t\t# shortcut corresponds to skip connection\n",
    "\t\telif x['type'] == 'shortcut':\n",
    "\t\t\tshortcut = EmptyLayer()\n",
    "\t\t\tmodule.add_module('shortcut_{}'.format(index), shortcut)\n",
    "\n",
    "class EmptyLayer(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(EmptyLayer, self).__init__()\n",
    "\n",
    "class DetectionLayer(nn.Module):\n",
    "\tdef __init__(self, anchors):\n",
    "\t\tsuper(DetectionLayer, self).__init__()\n",
    "\t\tself.anchors = anchors\n",
    "\n",
    "class Darknet(nn.Module):\n",
    "\tdef __init__(self, cfgfile):\n",
    "\t\tsuper(Darknet, self).__init__()\n",
    "\t\tself.blocks = parse_cfg(cfgfile)\n",
    "\t\tself.net_info, self.module_list = create_modules(self.blocks)\n",
    "\n",
    "\tdef forward(self, x, device=None):\n",
    "\t\tmodules = self.blocks[1:]\n",
    "\t\toutputs = {}  #We cache the outputs for the route layer\n",
    "\n",
    "\t\twrite = 0\n",
    "\t\tfor i, module in enumerate(modules):\n",
    "\t\t\tmodule_type = (module['type'])\n",
    "\n",
    "\t\t\tif module_type == 'convolutional' or module_type == 'upsample':\n",
    "\t\t\t\tx = self.module_list[i](x)\n",
    "\t\t\telif module_type == 'route':\n",
    "\t\t\t\tlayers = module['layers']\n",
    "\t\t\t\tlayers = [int(a) for a in layers]\n",
    "\n",
    "\t\t\t\tif (layers[0]) > 0:\n",
    "\t\t\t\t\tlayers[0] = layers[0] - i\n",
    "\t\t\t\t\n",
    "\t\t\t\tif len(layers) == 1:\n",
    "\t\t\t\t\tx = outputs[i + (layers[0])]\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tif (layers[1]) > 0:\n",
    "\t\t\t\t\t\tlayers[1] = layers[1] - i\n",
    "\n",
    "\t\t\t\t\tmap1 = outputs[i + layers[0]]\n",
    "\t\t\t\t\tmap2 = outputs[i + layers[1]]\n",
    "\n",
    "\t\t\t\t\tx = torch.cat((map1, map2), 1)\n",
    "\t\t\telif module_type == 'shortcut':\n",
    "\t\t\t\tfrom_ = int(module['from'])\n",
    "\t\t\t\tx = outputs[i-1] + outputs[i+from_]\n",
    "\t\t\telif module_type == 'yolo':\n",
    "\t\t\t\tanchors = self.module_list[i][0].anchors\n",
    "\t\t\t\t# Get the input dimensions\n",
    "\t\t\t\tinp_dim = int(self.net_info['height'])\n",
    "\n",
    "\t\t\t\t# Get the number of classes\n",
    "\t\t\t\tnum_classes = int(module['classes'])\n",
    "\n",
    "\t\t\t\t# Transform\n",
    "\t\t\t\tx = x.data\n",
    "\t\t\t\tx = predict_transform(x, inp_dim, anchors, num_classes, device)\n",
    "\t\t\t\tif not write:              #if no collector has been intialised.\n",
    "\t\t\t\t\tdetections = x\n",
    "\t\t\t\t\twrite = 1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tdetections = torch.cat((detections, x), 1)\n",
    "\n",
    "\t\t\toutputs[i] = x\n",
    "\t\t\n",
    "\t\treturn detections\n",
    "\n",
    "\t\tdef load_weights(self, weightfile):\n",
    "\t\t\tfp = open(weightfile, 'rb')\n",
    "\t\t\theader = np.fromfile(fp, dtype=np.int32, count=5)\n",
    "\t\t\tself.header = torch.from_numpy(header)\n",
    "\t\t\tself.seen = self.header[3]\n",
    "\t\t\tweights = np.fromfile(fd, dtype=np.float32)\n",
    "\n",
    "\t\t\tptr = 0\n",
    "\t\t\tfor i in range(len(self.module_list)):\n",
    "\t\t\t\tmodule_type = self.blocks[i + 1]['type']\n",
    "\n",
    "\t\t\t\t# If module_type is convolutional load weights, otherwise ignore.\n",
    "\t\t\t\tif module_type == 'convolutional':\n",
    "\t\t\t\t\tmodel = self.module_list[i]\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\tbatch_normalize = int(self.blocks[i + 1]['batch_normalize'])\n",
    "\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\tbatch_normalize = 0\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tconv = model[0]\n",
    "\n",
    "\t\t\t\t\tif (batch_normalize):\n",
    "\t\t\t\t\t\tbn = model[1]\n",
    "\n",
    "\t\t\t\t\t\t#Get the number of weights of Batch Norm Layer\n",
    "\t\t\t\t\t\tnum_bn_biases = bn.bias.numel()\n",
    "\n",
    "\t\t\t\t\t\t# Load the weights\n",
    "\t\t\t\t\t\tbn_biases = torch.from_numpy(weights[ptr:ptr + num_bn_biases])\n",
    "\t\t\t\t\t\tptr += num_bn_biases\n",
    "\n",
    "\t\t\t\t\t\tbn_weights = torch.from_numpy(weights[ptr:ptr + num_bn_biases])\n",
    "\t\t\t\t\t\tptr += num_bn_biases\n",
    "\n",
    "\t\t\t\t\t\tbn_running_mean = torch.from_numpy(weights[ptr:ptr + num_bn_biases])\n",
    "\t\t\t\t\t\tptr += num_bn_biases\n",
    "\n",
    "\t\t\t\t\t\tbn_running_var = torch.from_numpy(weights[ptr:ptr + num_bn_biases])\n",
    "\t\t\t\t\t\tptr += num_bn_biases\n",
    "\n",
    "\t\t\t\t\t\t# Cast the loaded weights into dims of model weights.\n",
    "\t\t\t\t\t\tbn_biases = bn_biases.view_as(bn.bias.data)\n",
    "\t\t\t\t\t\tbn_weights = bn_weights.view_as(bn.weight.data)\n",
    "\t\t\t\t\t\tbn_running_mean = bn_running_mean.view_as(bn.running_mean)\n",
    "\t\t\t\t\t\tbn_running_var = bn_running_var.view_as(bn.running_var)\n",
    "\n",
    "\t\t\t\t\t\t# Copy the data to model\n",
    "\t\t\t\t\t\tbn.bias.data.copy_(bn_biases)\n",
    "\t\t\t\t\t\tbn.weight.data.copy_(bn_weights)\n",
    "\t\t\t\t\t\tbn.running_mean.copy_(bn_running_mean)\n",
    "\t\t\t\t\t\tbn.running_var.copy_(bn_running_var)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t# Number of biases\n",
    "\t\t\t\t\t\tnum_biases = conv.bias.numel()\n",
    "\n",
    "\t\t\t\t\t\t# Load the weights\n",
    "\t\t\t\t\t\tconv_biases = torch.from_numpy(weights[ptr:ptr + num_biases])\n",
    "\t\t\t\t\t\tptr = ptr + num_biases\n",
    "\n",
    "\t\t\t\t\t\t# reshape the loaded weights according to the dims of the model weights\n",
    "\t\t\t\t\t\tconv_biases = conv_biases.view_as(conv.bias.data)\n",
    "\n",
    "\t\t\t\t\t\t# Finally copy the data\n",
    "\t\t\t\t\t\tconv.bias.data.copy_(conv_biases)\n",
    "\n",
    "\t\t\t\t\t# Let us load the weights for the Convolutional layers\n",
    "\t\t\t\t\tnum_weights = conv.weight.numel()\n",
    "\n",
    "\t\t\t\t\t# Do the same as above for weights\n",
    "\t\t\t\t\tconv_weights = torch.from_numpy(weights[ptr:ptr + num_weights])\n",
    "\t\t\t\t\tptr = ptr + num_weights\n",
    "\n",
    "\t\t\t\t\tconv_weights = conv_weights.view_as(conv.weight.data)\n",
    "\t\t\t\t\tconv.weight.data.copy_(conv_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "beadf95f16862a7393e5fa829bfbfa3e6e0a11534280b92e7d2b4d010105fa65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
